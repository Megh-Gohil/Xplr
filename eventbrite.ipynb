{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "import random\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "chrome_options = Options()\n",
    "filename = \"data\"\n",
    "link = \"https://www.eventbrite.com/d/india--mumbai/all-events/?page=\"\n",
    "\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "record = []\n",
    "e = []\n",
    "le = 0\n",
    "\n",
    "event_ids = []\n",
    "\n",
    "def Selenium_extractor():\n",
    "    \n",
    "    action = ActionChains(browser)\n",
    "    # with open(\"eventbrite_data/ev.html\", \"w\") as file:\n",
    "    #     file.write(browser.page_source)\n",
    "    time.sleep(2)\n",
    "\n",
    "    a = browser.find_elements(By.XPATH, '//div[@data-testid=\"event-card-tracking-layer\"]')\n",
    "    \n",
    "    for i in a:\n",
    "        event_ids.append(i.get_attribute(\"data-event-id\"))\n",
    "        \n",
    "\n",
    "for i in range(7):\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        browser.get(str(link) + str(i+1))\n",
    "        time.sleep(2)\n",
    "        Selenium_extractor()\n",
    "    except:\n",
    "        continue\n",
    "browser.quit()\n",
    "unique_event_ids = [*set(event_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "website1 = \"https://www.eventbrite.com/api/v3/destination/events/?event_ids=\"\n",
    "website2 = \"&expand=event_sales_status,image,primary_venue,saves,ticket_availability,primary_organizer,public_collections\"\n",
    "for i in unique_event_ids:\n",
    "    cmd = subprocess.Popen([\"GET\", website1 + str(i) + website2], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    time.sleep(2)\n",
    "    output, error = (cmd.communicate())\n",
    "    time.sleep(2)\n",
    "    with open(\"json_data/event\" + str(i) + \".json\", \"w\") as file:\n",
    "        file.write((output.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "df = pd.DataFrame({\"Name\" : [], \"image_link\" : [], \"tickets_url\" : [], \"start_date\" : [],\"start_time\" : [],  \"end_date\" : [], \"end_time\" : [],\"venue\" : [], \"address_1\" : [], \"address_2\" : [], \"organizer\" : [], \"organizer_url\" : [],\"url\" : []})\n",
    "for i in unique_event_ids:\n",
    "    with open(\"json_data/event\" + str(i) + \".json\") as data_file:\n",
    "        # print(type(data_file))\n",
    "        parsed_data = json.load(data_file)\n",
    "        # print(type(parsed_data))\n",
    "        # print(type(json.load(data_file)))\n",
    "    event = parsed_data['events'][0]\n",
    "    event_data = []\n",
    "    try:\n",
    "        event_data.append(event['name'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['image']['url'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['tickets_url'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['start_date'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['start_time'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['end_date'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:    \n",
    "        event_data.append(event['end_time'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:    \n",
    "        event_data.append(event['primary_venue']['name'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:    \n",
    "        event_data.append(event['primary_venue']['address']['address_1'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['primary_venue']['address']['address_2'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['primary_organizer']['name'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['primary_organizer']['url'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    try:\n",
    "        event_data.append(event['url'])\n",
    "    except:\n",
    "        event_data.append(\"Unavailable\")\n",
    "    \n",
    "    df.loc[len(df)] = event_data\n",
    "\n",
    "output_path='data_scrapped/eventbrite_data.csv'\n",
    "df.to_csv(output_path, mode='a', header=not os.path.exists(output_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
